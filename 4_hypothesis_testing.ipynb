{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29e7c28",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ae676",
   "metadata": {},
   "source": [
    "This notebook is going to cover **hypothesis testing**, which measures whether a finding is likely to have occurred by chance rather than because of a hypothesized variable. Think of testing a new drug that is supposed to reduce the duration of a cold. If the average time of recovery with the drug is less than the average time without the drug, it has to be enough of a difference so that it's unlikely to have been due to random chance. It could very well be the drug had no effect. \n",
    "\n",
    "Let's get some intuition first by exploring the most critical building block for this reasoning: the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b500f28",
   "metadata": {},
   "source": [
    "## P-Value Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabf72f",
   "metadata": {},
   "source": [
    "When somebody says something is statistically significant, what does that mean? It is a phrase thrown around a lot, but few people stop and articulate how statistical significance works on a mathematical level. To understand statistical significance, we can go back to the invention of the p-value in 1925. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbefa4c5",
   "metadata": {},
   "source": [
    "A mathematician named Ronald Fisher was at a party. One of his colleagues Muriel Bristol claimed she could detect when tea was poured before milk simply by tasting it. Intrigued by the claim, Ronald set up an experiment on the spot.\n",
    "\n",
    "He prepared eight cups of tea. Four had milk poured first; the other four had tea poured first. He then asked her to identify the pour order of each. Remarkably, she identified them all correctly, and if she was simply guessing the probability of this happening by chance is 1 in 70, or 0.01428571. This is what we call the **p-value**, the probablity something happened by random luck rather than because of a hypothesized explanation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96208b5e",
   "metadata": {},
   "source": [
    "![svg image](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   version="1.1"
   id="Layer_1"
   x="0px"
   y="0px"
   viewBox="0 0 185.46362 121.54538"
   xml:space="preserve"
   sodipodi:docname="coffee-tea-kettle-icon.svg"
   width="185.46362"
   height="121.54538"
   inkscape:version="1.2.2 (b0a84865, 2022-12-01)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg"><defs
     id="defs180" /><sodipodi:namedview
     id="namedview178"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     showgrid="false"
     inkscape:zoom="1.7497189"
     inkscape:cx="166.59819"
     inkscape:cy="51.151074"
     inkscape:window-width="1440"
     inkscape:window-height="847"
     inkscape:window-x="0"
     inkscape:window-y="25"
     inkscape:window-maximized="1"
     inkscape:current-layer="Layer_1" /><g
     id="g175"
     transform="translate(61.82338)"><path
       d="m 21.46,51.6 c -0.57,3.12 -0.83,5.95 -0.84,8.53 -0.01,2.58 0.23,4.9 0.68,6.99 0.36,1.47 0.84,2.91 1.44,4.3 0.58,1.36 1.28,2.67 2.1,3.92 1.37,2.09 3.07,4 5.13,5.69 1.94,1.59 4.19,2.97 6.78,4.09 l 0.17,-0.01 h 47.31 c 3.23,-1.26 5.99,-2.99 8.29,-5.07 2.46,-2.22 4.4,-4.85 5.83,-7.72 0.96,-1.92 1.69,-3.96 2.21,-6.06 0.53,-2.15 0.82,-4.38 0.9,-6.62 0.07,-2.24 -0.08,-4.5 -0.44,-6.74 -0.36,-2.23 -0.95,-4.45 -1.74,-6.59 -1.41,-3.82 -3.48,-7.42 -6.18,-10.54 -2.53,-2.91 -5.6,-5.4 -9.21,-7.26 l -46.45,0.35 c -0.07,0.02 -0.15,0.04 -0.22,0.05 l -0.18,0.02 c -3.07,2.09 -5.75,4.61 -8.02,7.41 -2.39,2.95 -4.31,6.22 -5.73,9.64 -0.38,0.91 -0.72,1.83 -1.02,2.76 -0.3,0.93 -0.57,1.86 -0.8,2.8 z m 65.53,36.43 v 3.1 c 0,0.79 -0.16,1.54 -0.44,2.23 -0.3,0.71 -0.73,1.36 -1.27,1.9 l -0.02,0.02 c -0.53,0.53 -1.17,0.96 -1.87,1.25 -0.69,0.29 -1.44,0.44 -2.23,0.44 H 40.43 c -0.73,0 -1.42,-0.15 -2.06,-0.41 -0.66,-0.27 -1.26,-0.68 -1.75,-1.17 l -0.09,-0.1 c -0.47,-0.49 -0.85,-1.07 -1.1,-1.72 -0.25,-0.62 -0.39,-1.29 -0.39,-1.99 v -3.1 c -0.94,-0.42 -1.84,-0.86 -2.69,-1.33 -0.91,-0.5 -1.78,-1.04 -2.61,-1.6 l -0.1,-0.01 C 27.58,85.35 25.5,84.96 23.47,84.34 21.55,83.76 19.67,82.97 17.9,81.97 16.21,81.01 14.61,79.85 13.16,78.48 11.79,77.18 10.55,75.69 9.47,73.99 6.84,69.83 5.5,66.61 4.78,63.48 4.07,60.35 3.98,57.33 3.88,53.56 L 3.83,51.72 C 3.81,51.09 3.79,50.41 3.75,49.67 3.68,47.95 3.56,46.24 3.39,44.55 3.22,42.84 3,41.17 2.71,39.5 2.42,37.86 2.07,36.24 1.65,34.66 1.22,33.07 0.72,31.52 0.13,30.01 c -0.19,-0.48 -0.16,-1 0.03,-1.44 0.19,-0.44 0.56,-0.8 1.04,-0.99 0.13,-0.05 0.26,-0.08 0.39,-0.1 0.13,-0.02 0.27,-0.03 0.4,-0.02 l 8.48,0.15 c 0.39,0.01 0.74,0.13 1.04,0.33 0.3,0.21 0.54,0.51 0.68,0.86 l 7.16,16.96 0.06,-0.15 c 0.13,-0.33 0.27,-0.69 0.42,-1.06 1.57,-3.79 3.71,-7.41 6.37,-10.68 2.51,-3.08 5.48,-5.85 8.87,-8.14 v -3.36 c 0,-0.6 0.12,-1.17 0.34,-1.7 0.23,-0.55 0.56,-1.04 0.97,-1.45 L 36.4,19.2 c 0.41,-0.4 0.89,-0.73 1.42,-0.95 0.53,-0.22 1.1,-0.34 1.7,-0.34 h 0.84 c 0.52,-0.84 1.08,-1.63 1.69,-2.37 0.65,-0.8 1.36,-1.54 2.12,-2.22 0.87,-0.78 1.81,-1.48 2.82,-2.11 1.01,-0.62 2.1,-1.16 3.27,-1.6 0.5,-0.19 1.02,-0.37 1.55,-0.52 0.54,-0.16 1.12,-0.3 1.71,-0.42 L 54.25,8.53 C 54.16,8.27 54.09,8.01 54.03,7.73 53.94,7.31 53.9,6.87 53.9,6.44 c 0,-0.87 0.17,-1.7 0.49,-2.46 0.33,-0.79 0.81,-1.5 1.4,-2.09 0.59,-0.59 1.3,-1.07 2.09,-1.4 C 58.63,0.17 59.46,0 60.33,0 c 0.87,0 1.7,0.17 2.46,0.49 0.79,0.33 1.5,0.81 2.09,1.4 0.59,0.59 1.07,1.3 1.4,2.09 0.31,0.76 0.49,1.59 0.49,2.46 0,0.41 -0.04,0.81 -0.12,1.21 -0.05,0.24 -0.11,0.48 -0.18,0.71 0.47,0.07 0.93,0.15 1.4,0.25 0.46,0.09 0.9,0.2 1.32,0.31 1.4,0.37 2.71,0.86 3.93,1.47 1.23,0.61 2.38,1.34 3.43,2.17 0.94,0.74 1.8,1.58 2.6,2.5 0.75,0.87 1.44,1.82 2.07,2.85 h 0.79 c 0.6,0 1.17,0.12 1.7,0.34 0.55,0.23 1.04,0.56 1.45,0.97 l 0.02,0.02 c 0.4,0.41 0.73,0.89 0.95,1.43 0.22,0.53 0.34,1.1 0.34,1.7 v 3.26 c 1.36,0.75 2.65,1.59 3.87,2.49 1.24,0.92 2.4,1.91 3.49,2.97 4.24,-1.94 8.2,-2.52 11.76,-2.05 4.01,0.53 7.52,2.38 10.36,5.1 1.6,1.53 2.98,3.33 4.1,5.32 1.15,2.02 2.04,4.24 2.65,6.57 0.61,2.33 0.93,4.78 0.94,7.25 0.01,2.39 -0.28,4.81 -0.9,7.16 -1.33,5.1 -4.16,9.92 -8.76,13.64 -4.03,3.25 -9.42,5.66 -16.34,6.65 h -0.01 c -0.12,0.02 -0.24,0.02 -0.36,0.01 l -0.13,-0.01 c -1.37,1.52 -2.92,2.92 -4.66,4.16 -1.65,1.19 -3.49,2.25 -5.49,3.14 z M 38.8,88.96 v 2.61 c 0,0.21 0.04,0.41 0.11,0.59 0.07,0.19 0.18,0.36 0.32,0.51 l 0.05,0.05 c 0.3,0.3 0.7,0.48 1.15,0.48 h 40.73 c 0.28,0 0.55,-0.06 0.79,-0.16 0.25,-0.1 0.48,-0.26 0.67,-0.45 0.19,-0.19 0.35,-0.42 0.45,-0.67 0.1,-0.24 0.16,-0.51 0.16,-0.79 v -2.17 z m 43.91,-64.2 v -2.39 c 0,-0.09 -0.02,-0.18 -0.05,-0.26 -0.04,-0.08 -0.09,-0.16 -0.15,-0.23 -0.06,-0.06 -0.14,-0.12 -0.22,-0.15 -0.08,-0.03 -0.17,-0.05 -0.26,-0.05 h -42.5 c -0.09,0 -0.18,0.02 -0.26,0.05 -0.08,0.04 -0.16,0.09 -0.23,0.15 -0.12,0.13 -0.2,0.3 -0.2,0.48 v 2.73 z M 44.97,17.91 h 31.68 c -0.29,-0.35 -0.58,-0.69 -0.89,-1.01 -0.48,-0.5 -0.99,-0.97 -1.53,-1.4 -0.85,-0.68 -1.78,-1.26 -2.78,-1.75 -1,-0.49 -2.07,-0.89 -3.22,-1.2 -0.36,-0.1 -0.72,-0.18 -1.1,-0.26 H 67.12 C 66.75,12.21 66.34,12.14 65.91,12.08 65.46,12.01 65.01,11.95 64.57,11.91 64.12,11.86 63.66,11.82 63.19,11.8 H 63.17 C 62.93,11.78 62.69,11.72 62.47,11.61 62.25,11.5 62.05,11.35 61.88,11.15 61.54,10.76 61.4,10.26 61.43,9.78 61.47,9.3 61.69,8.83 62.08,8.5 62.23,8.37 62.37,8.23 62.48,8.08 62.6,7.93 62.7,7.76 62.78,7.58 62.86,7.41 62.92,7.23 62.96,7.04 63,6.86 63.02,6.66 63.02,6.46 63.02,6.09 62.95,5.75 62.82,5.43 62.69,5.1 62.49,4.81 62.24,4.56 61.99,4.31 61.7,4.11 61.37,3.98 61.06,3.85 60.71,3.78 60.34,3.78 59.98,3.78 59.63,3.85 59.32,3.98 58.99,4.12 58.7,4.32 58.45,4.56 58.2,4.81 58,5.1 57.87,5.43 l -0.01,0.02 c -0.12,0.31 -0.19,0.65 -0.19,1.01 0,0.21 0.02,0.42 0.06,0.6 0.04,0.19 0.11,0.38 0.19,0.55 l 0.01,0.03 C 58,7.8 58.1,7.96 58.22,8.1 c 0.13,0.16 0.27,0.3 0.42,0.43 l 0.03,0.03 c 0.18,0.15 0.33,0.34 0.44,0.55 0.12,0.22 0.19,0.46 0.21,0.72 0.04,0.52 -0.12,1 -0.43,1.37 l -0.02,0.02 c -0.31,0.35 -0.75,0.6 -1.25,0.64 h -0.03 c -0.56,0.05 -1.13,0.12 -1.69,0.2 -0.56,0.08 -1.1,0.18 -1.63,0.29 -0.5,0.1 -0.98,0.22 -1.44,0.35 -0.45,0.13 -0.86,0.26 -1.24,0.41 l -0.02,0.01 c -0.93,0.36 -1.8,0.79 -2.61,1.29 -0.82,0.5 -1.58,1.07 -2.28,1.71 -0.4,0.36 -0.78,0.74 -1.15,1.14 -0.19,0.21 -0.38,0.43 -0.56,0.65 z m 55.42,58.48 c 4.99,-1.17 8.92,-3.22 11.9,-5.82 3.56,-3.1 5.77,-6.99 6.83,-11.08 0.53,-2.04 0.78,-4.14 0.78,-6.22 -0.01,-2.15 -0.29,-4.27 -0.82,-6.31 -0.52,-2 -1.28,-3.91 -2.26,-5.63 l -0.01,-0.03 c -0.95,-1.68 -2.11,-3.2 -3.44,-4.47 -2.19,-2.09 -4.88,-3.54 -7.97,-4.01 -2.68,-0.41 -5.66,-0.08 -8.87,1.19 1.29,1.56 2.44,3.23 3.44,4.97 1.12,1.93 2.06,3.95 2.83,6.03 0.87,2.36 1.51,4.81 1.91,7.28 0.4,2.48 0.57,4.98 0.49,7.47 -0.08,2.52 -0.41,5.01 -1,7.43 -0.58,2.36 -1.4,4.65 -2.48,6.81 -0.27,0.54 -0.56,1.08 -0.87,1.62 -0.15,0.25 -0.3,0.51 -0.46,0.77 z M 17.65,68.01 C 17.39,66.95 17.19,65.88 17.04,64.8 16.89,63.7 16.78,62.59 16.73,61.47 16.66,59.79 16.7,58.1 16.86,56.4 c 0.16,-1.67 0.42,-3.35 0.8,-5.01 L 9.18,31.34 4.55,31.26 c 0.38,1.16 0.71,2.33 1,3.5 0.34,1.36 0.62,2.72 0.86,4.1 0.3,1.72 0.53,3.47 0.71,5.25 0.18,1.77 0.3,3.57 0.38,5.38 v 0 c 0.03,0.67 0.05,1.35 0.07,2.02 l 0.06,1.94 c 0.09,3.47 0.17,6.25 0.81,9.08 0.64,2.82 1.85,5.72 4.2,9.45 0.9,1.43 1.95,2.68 3.1,3.77 1.22,1.16 2.57,2.13 4,2.95 0.82,0.46 1.66,0.87 2.53,1.23 0.47,0.19 0.94,0.37 1.42,0.54 -0.7,-0.83 -1.38,-1.72 -2.01,-2.68 -0.91,-1.38 -1.74,-2.92 -2.44,-4.61 -0.32,-0.78 -0.62,-1.61 -0.89,-2.46 -0.27,-0.88 -0.5,-1.77 -0.7,-2.71 z"
       id="path173" /></g><path
     d="m 34.21566,56.113205 c -0.43394,-0.560282 -0.32958,-1.362255 0.23071,-1.796199 0.56028,-0.433944 1.36225,-0.329578 1.79619,0.230705 1.45015,1.884086 0.84043,3.916482 0.13733,6.261977 -0.68113,2.263101 -1.46662,4.899723 0.18676,7.50888 0.37901,0.598733 0.20324,1.38972 -0.39549,1.774227 -0.59874,0.379015 -1.38972,0.20324 -1.77423,-0.395493 -2.27958,-3.597891 -1.31282,-6.833246 -0.47789,-9.618178 0.50535,-1.675354 0.94479,-3.130989 0.29662,-3.965919 z M 48.393,74.92111 v 8.772261 c 0.46141,-0.01648 0.94479,-0.03845 1.43366,-0.06042 3.42212,-0.170282 6.93212,-0.340564 9.58522,2.356481 1.72479,1.752255 2.54874,4.262539 2.39493,6.899161 -0.0769,1.373241 -0.42296,2.790425 -1.04366,4.15268 -0.61521,1.351269 -1.49958,2.647608 -2.66958,3.795637 -2.79043,2.74648 -7.19029,4.66902 -13.32043,4.47127 -0.80747,1.20845 -1.73029,2.33451 -2.75198,3.36169 -3.93296,3.93297 -9.35451,6.37184 -15.31987,6.37184 h -5.01508 c -5.96535,0 -11.38691,-2.43887 -15.31987,-6.37184 C 2.43887,104.73142 0,99.304371 0,93.339014 V 74.92111 c 0,-0.708593 0.57676,-1.285354 1.28535,-1.285354 h 45.82229 c 0.7086,0 1.28536,0.571268 1.28536,1.285354 z m 0,11.331982 v 7.085922 c 0,3.361693 -0.77451,6.553104 -2.15324,9.398456 4.61409,-0.12084 7.93183,-1.64239 10.0631,-3.740704 0.9393,-0.922818 1.64789,-1.960988 2.13677,-3.032116 0.48338,-1.060142 0.75253,-2.158734 0.81296,-3.229862 0.10985,-1.933523 -0.46141,-3.740708 -1.66437,-4.960145 -1.84564,-1.878594 -4.77888,-1.730284 -7.63522,-1.59296 -0.51634,0.03296 -1.02718,0.06042 -1.56,0.07141 z m -2.57071,7.085922 V 76.20097 H 2.5707 v 17.138044 c 0,5.256765 2.15324,10.035646 5.6193,13.501706 3.46606,3.46606 8.24494,5.6193 13.50171,5.6193 h 5.01507 c 5.25677,0 10.03564,-2.15324 13.5017,-5.6193 3.46057,-3.46606 5.61381,-8.244941 5.61381,-13.501706 z M 1.7907,121.54538 c -0.70859,0 -1.28535,-0.57676 -1.28535,-1.28536 0,-0.70859 0.57676,-1.28535 1.28535,-1.28535 h 45.53666 c 0.7086,0 1.28536,0.57676 1.28536,1.28535 0,0.7086 -0.57676,1.28536 -1.28536,1.28536 z M 12.8755,56.113205 c -0.43394,-0.560282 -0.32958,-1.362255 0.2307,-1.796199 0.56029,-0.433944 1.36226,-0.329578 1.7962,0.230705 1.45015,1.884086 0.84043,3.916482 0.13733,6.261977 -0.68113,2.263101 -1.46662,4.899723 0.18676,7.50888 0.37901,0.598733 0.20324,1.38972 -0.39549,1.774227 -0.59874,0.379015 -1.38972,0.20324 -1.77423,-0.395493 -2.27958,-3.597891 -1.31282,-6.833246 -0.47789,-9.618178 0.50535,-1.675354 0.9393,-3.130989 0.29662,-3.965919 z m 10.67283,0 c -0.43395,-0.560282 -0.32958,-1.362255 0.2307,-1.796199 0.56028,-0.433944 1.36226,-0.329578 1.7962,0.230705 1.45014,1.884086 0.84042,3.916482 0.13732,6.261977 -0.68112,2.263101 -1.46662,4.899723 0.18677,7.50888 0.37901,0.598733 0.20323,1.38972 -0.3955,1.774227 -0.59873,0.379015 -1.38972,0.20324 -1.77423,-0.395493 -2.28507,-3.597891 -1.31281,-6.833246 -0.47788,-9.618178 0.50535,-1.675354 0.93929,-3.130989 0.29662,-3.965919 z"
     id="path320"
     style="stroke-width:0.999999" /></svg>
)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6efaa4",
   "metadata": {},
   "source": [
    "When you have a p-value that's very low (conventionally < 0.05), that indicates the event was unlikely to have happened by random chance. Therefore we are inclined to think that Muriel has this special ability to detect when tea was poured before the milk, because if she was just randomly guessing she only had a 1.42% chance of succeeding. \n",
    "\n",
    "This example does not capture every nuance of a p-value, but it does provide the essence of it. Let's see how this concept applies with a sample mean and the normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfd77e",
   "metadata": {},
   "source": [
    "## Two-Tailed Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b9665",
   "metadata": {},
   "source": [
    "Let's bring in the lightbulb dataset and calculate its mean, standard deviation, and count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np \n",
    "\n",
    "X = pd.read_csv(\"https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/distribution/lightbulb_data.csv\") \\\n",
    "    .squeeze()\n",
    "X\n",
    "\n",
    "mean, std, n = X.mean(), X.std(), X.count()\n",
    "print(\"MEAN: \", mean)\n",
    "print(\"STD: \", std)\n",
    "print(\"n: \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca0fdf",
   "metadata": {},
   "source": [
    "Based on this data, we can infer that there is a 95% probability the lightbulb will last approximately between 571.3 hours and 773.1 hours as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "# .95 area \n",
    "a,b = norm.ppf(.025, mean, std), norm.ppf(.975, mean, std)\n",
    "ix = np.linspace(a, b)\n",
    "iy =  norm.pdf(ix, mean, std)\n",
    "verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "ax.add_patch(poly)\n",
    "\n",
    "# add text labels\n",
    "plt.text(mean, .003, '.95', fontsize = 22, ha='center')\n",
    "plt.text(a, norm.pdf(a,mean,std), round(a,2), fontsize = 16, ha='right', color='blue')\n",
    "plt.text(b, norm.pdf(b,mean,std), round(b,2), fontsize = 16, ha='left', color='blue')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f57f7f",
   "metadata": {},
   "source": [
    "We can calculate that center range capturing the .95 area by using the inverse cumulative density function (the `ppf()` function in SciPy) as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35621cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "print(norm.ppf(.025, mean, std), norm.ppf(.975, mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bba9b",
   "metadata": {},
   "source": [
    "Let's say an engineer made a design change and tested 31 light bulbs with this new design tweak. He happily reports that the mean in this new sample is 790. Now consider this... is this a coincidence? Let's look at this new mean compared to our current distribution of lightbulb lifespans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c460c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "new_mean = 790\n",
    "\n",
    "# plot chart\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "# .95 area \n",
    "a,b = norm.ppf(.025, mean, std), norm.ppf(.975, mean, std)\n",
    "ix = np.linspace(a, b)\n",
    "iy =  norm.pdf(ix, mean, std)\n",
    "verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "ax.add_patch(poly)\n",
    "\n",
    "# add text labels\n",
    "plt.vlines(x = new_mean, ymin = 0, ymax = .005,\n",
    "           colors = 'red',\n",
    "           label = r\"\\bar{x}_{new}\")\n",
    "\n",
    "plt.text(mean, .003, '.95', fontsize = 22, ha='center')\n",
    "plt.text(new_mean, .005, round(new_mean,2), fontsize = 16, ha='center', va='bottom', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb3c86",
   "metadata": {},
   "source": [
    "Hmm... take notice here that if we want to be 95% confident that the engineering change had an effect, logically the mean of the new sample must fall outside that .95 range (due to the central limit theorem). Therefore, we are inclined to believe with 95% confidence that the engineering change did improve the design.\n",
    "\n",
    "Let's formalize these ideas a bit more.  We claim the **null hypothesis ($ H_0 $)** is the status quo: the mean is 672.2 and the engineering change had no effect. But the **alternative hypothesis ($ H_1 $)** is the mean *is not* 672.2 with the new engineering design, and we believe it did have an effect enough to reject the null hypothesis. \n",
    "\n",
    "$$\n",
    "H_0: \\mu = 672.2 \n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\mu \\ne 672.2 \n",
    "$$\n",
    "\n",
    "Because this new mean of 790 does fall outside that 95% confidence range, we call it **statistically significant**, meaning it is unlikely to be coincidental enouugh that we can reject the null hypothesis and promote the alternative hypothesis. \n",
    "\n",
    "But *how unlikely* is it we would have observed 790 with the current lightbulb design? We can roughly say it falls outside the 95% \"coincidence\" range as shown above, but by how much? This is where the **p-value** once again comes in. Let's take a look at area left over in each tail, which is going to be $ .025 $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d047fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "new_mean = 790\n",
    "\n",
    "# plot chart\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "def plot_tail(a, b): \n",
    "    # p-value areas\n",
    "    ix = np.linspace(a, b)\n",
    "    iy = norm.pdf(ix, mean, std)\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "\n",
    "plot_tail(mean-std*3, norm.ppf(.025, mean, std))\n",
    "plot_tail(norm.ppf(.975, mean, std), mean+std*3)\n",
    "\n",
    "# add text labels\n",
    "plt.vlines(x = new_mean, ymin = norm.pdf(new_mean, mean, std), ymax = .005,\n",
    "           colors = 'red',\n",
    "           label = r\"\\bar{x}_{new}\")\n",
    "\n",
    "plt.text(555, .0001, '.025', fontsize = 12, ha='center')\n",
    "plt.text(775, .0001, '.025', fontsize = 12, ha='left')\n",
    "plt.text(new_mean, .005, round(new_mean,2), fontsize = 16, ha='center', va='bottom', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca54afa",
   "metadata": {},
   "source": [
    "However, this is not our p-value. The p-value has to capture any probability that is of equal or less value on both sides where we observed the new mean.  After all, we are trying to prove significance, and that includes anything that is equally or less likely to happen. Let's visualize just that area on both sides, which in total will be the p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44625f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "new_mean = 790\n",
    "\n",
    "# plot chart\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "def plot_tail(a, b): \n",
    "    # p-value areas\n",
    "    ix = np.linspace(a, b)\n",
    "    iy = norm.pdf(ix, mean, std)\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "\n",
    "plot_tail(mean-std*3, norm.ppf(1.0 - norm.cdf(new_mean, mean, std), mean, std))\n",
    "plot_tail(new_mean, mean+std*3)\n",
    "\n",
    "# add text labels\n",
    "plt.vlines(x = new_mean, ymin = 0, ymax = .005,\n",
    "           colors = 'red',\n",
    "           label = r\"\\bar{x}_{new}\")\n",
    "\n",
    "one_side_p_value  = 1.0 - norm.cdf(new_mean, mean, std)\n",
    "print(one_side_p_value*2)\n",
    "plt.text(530, .0005, round(one_side_p_value, 3), fontsize = 12, ha='center')\n",
    "plt.text(800, .0005, round(one_side_p_value, 3), fontsize = 12, ha='left')\n",
    "plt.text(new_mean, .005, round(new_mean,2), fontsize = 16, ha='center', va='bottom', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652ce99",
   "metadata": {},
   "source": [
    "So we are left  approximately with a p-value of $ 0.022 $, which is divided to both tails as $ 0.011 $. While trying to identify the ranges of these tails requires some deductive math and a bit of code, calculating the p-value itself can be done in two lines of code. We can simply calculate the area of the right tail using the CDF at the new sample mean (and subtract from 1.0 to get the right area, not the left), and then doubling it to take advantage of the symmetry of the left tail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area of right tail \n",
    "p_value_right_tail = 1.0 -  norm.cdf(new_mean, mean, std)\n",
    "\n",
    "# p-value of both tails (symmetrical)\n",
    "p_value = p_value_right_tail*2 \n",
    "\n",
    "print(p_value) # 0.02212358425605565"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed032e6",
   "metadata": {},
   "source": [
    "So practically speaking, how do we interpet this p-value? We say that the re-enginerred lightbulb life span of 790  is 2.2% likely to have happened by chance (including probability of equally or less likely events). If our threshold is 95% confidence, or a 5% level of significance, $ 0.022 $ is less than $ 0.05 $ so we can reject our null hypothesis, and promote the alternative hypothesis that our re-engineered lightbulb is an improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc9502",
   "metadata": {},
   "source": [
    "Alternatively, let's say the new lightbulb only improved the sample mean to 750. Notice below this would not be in the \"statistically significant\" range even though it is higher than the current mean  of 672.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f0be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "new_mean = 750\n",
    "\n",
    "# plot chart\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "def plot_tail(a, b): \n",
    "    # p-value areas\n",
    "    ix = np.linspace(a, b)\n",
    "    iy = norm.pdf(ix, mean, std)\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "\n",
    "plot_tail(mean-std*3, norm.ppf(.025, mean, std))\n",
    "plot_tail(norm.ppf(.975, mean, std), mean+std*3)\n",
    "\n",
    "# add text labels\n",
    "plt.vlines(x = new_mean, ymin = 0, ymax = .005,\n",
    "           colors = 'red',\n",
    "           label = r\"\\bar{x}_{new}\")\n",
    "\n",
    "plt.text(555, .0001, '.025', fontsize = 12, ha='center')\n",
    "plt.text(775, .0001, '.025', fontsize = 12, ha='left')\n",
    "plt.text(new_mean, .005, round(new_mean,2), fontsize = 16, ha='center', va='bottom', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc62ec",
   "metadata": {},
   "source": [
    "At a 95% threshold, we cannot attribute this lightbulb to perform significantly better than the current one because there's a good chance it was just by random luck and performs the same as the current lightbulb. How much of a chance? Well again, that is the p-value and we can calculate that. We find it is $ 0.13 $, and that is much higher than $ 0.05 $. Therefore we cannot reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mean = 750 \n",
    "\n",
    "# area of right tail \n",
    "p_value_right_tail = 1.0 -  norm.cdf(new_mean, mean, std)\n",
    "\n",
    "# p-value of both tails (symmetrical)\n",
    "p_value = p_value_right_tail*2 \n",
    "\n",
    "print(p_value) # 0.13072525593787487"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdc86f",
   "metadata": {},
   "source": [
    "And just for good measure, here is the p-value area visualized for a new sample mean of 750. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73cdcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "new_mean = 750\n",
    "\n",
    "# plot chart\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "def plot_tail(a, b): \n",
    "    # p-value areas\n",
    "    ix = np.linspace(a, b)\n",
    "    iy = norm.pdf(ix, mean, std)\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "\n",
    "plot_tail(mean-std*3, norm.ppf(1.0 - norm.cdf(new_mean, mean, std), mean, std))\n",
    "plot_tail(new_mean, mean+std*3)\n",
    "\n",
    "# add text labels\n",
    "plt.vlines(x = new_mean, ymin = 0, ymax = .005,\n",
    "           colors = 'red',\n",
    "           label = r\"\\bar{x}_{new}\")\n",
    "\n",
    "one_side_p_value  = 1.0 - norm.cdf(new_mean, mean, std)\n",
    "print(one_side_p_value*2)\n",
    "plt.text(555, .0015, round(one_side_p_value, 3), fontsize = 12, ha='center')\n",
    "plt.text(775, .0015, round(one_side_p_value, 3), fontsize = 12, ha='left')\n",
    "plt.text(new_mean, .005, round(new_mean,2), fontsize = 16, ha='center', va='bottom', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3953a80",
   "metadata": {},
   "source": [
    "## One-Tailed Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf71534",
   "metadata": {},
   "source": [
    "While not often as robust two-tailed testing, there is another way to perform hypothesis testing via **one-tailed testing**. We express null and alternative hypotheses as inequalities. we would be \n",
    "\n",
    "$$\n",
    "H_0: \\mu <= 672.2 \n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\mu > 672.2 \n",
    "$$\n",
    "\n",
    "Let's visualize the p-value for one-tailed testing as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97017daa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "new_mean = 790\n",
    "\n",
    "# plot chart\n",
    "fig, ax = plt.subplots()\n",
    "x_range = np.arange(mean-std*3, mean+std*3, .01) \n",
    "ax.plot(x_range, norm.pdf(x_range, mean, std)) # bell curve \n",
    "\n",
    "def plot_tail(a, b): \n",
    "    # p-value areas\n",
    "    ix = np.linspace(a, b)\n",
    "    iy = norm.pdf(ix, mean, std)\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "\n",
    "plot_tail(new_mean, mean+std*3)\n",
    "\n",
    "# add text labels\n",
    "plt.vlines(x = new_mean, ymin = 0, ymax = .005,\n",
    "           colors = 'red',\n",
    "           label = r\"\\bar{x}_{new}\")\n",
    "\n",
    "one_side_p_value  = 1.0 - norm.cdf(new_mean, mean, std)\n",
    "plt.text(800, .0005, round(one_side_p_value, 3), fontsize = 12, ha='left')\n",
    "plt.text(new_mean, .005, round(new_mean,2), fontsize = 16, ha='center', va='bottom', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2d0aa",
   "metadata": {},
   "source": [
    "This simplifies the calculation of the p-value, by only including the tail that matches the alternative hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mean = 790 \n",
    "\n",
    "# area of right tail \n",
    "p_value = 1.0 -  norm.cdf(new_mean, mean, std)\n",
    "\n",
    "print(p_value) # 0.011061792128027825"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31726c",
   "metadata": {},
   "source": [
    "How does this affect whether we reject the null hypothesis? Ask yourself this: which one sets a higher threshold? You will notice that even when our objective is to show we may have decreased/increased something (the lifespan of the bulb), reframing our hypothesis to show any impact (greater or lesser) creates a higher significance threshold. If our significance threshold is a p-value of .05 or less, our one-tailed test had a much smaller p-value .011 as opposed to the two-tailed test, which was about double that at p-value .022.\n",
    "\n",
    "For this reason, it is preferable to use the two-tailed test over one-tailed in many situations. It does not bias the test in one direction and it also sets a higher threshold for acceptance of the alternative hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad9915",
   "metadata": {},
   "source": [
    "## Dealing with Smaller Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e1c99",
   "metadata": {},
   "source": [
    "As discussed in the previous section, if you have a smaller sample (n<31) then swap out the normal distribution with the T-distribution. For example, let's say the new lightbulb design had only a sample size of 5. We can calculate the two-tailed p-value as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "new_mean = 790 \n",
    "n = 5\n",
    "\n",
    "# area of right tail \n",
    "p_value_right_tail = 1.0 -  t.cdf(new_mean, df=n-1, loc=mean, scale=std)\n",
    "\n",
    "# p-value of both tails (symmetrical)\n",
    "p_value = p_value_right_tail*2 \n",
    "\n",
    "print(p_value) # 0.08401989317568481"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df5c57",
   "metadata": {},
   "source": [
    "Our p-value is much larger: 0.084. Because this does not pass our threshold of $ .05 $ we cannot reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d9741",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f75296",
   "metadata": {},
   "source": [
    "An online gaming platform is trying to increase the playtime of its users with a new reward system. Typically, the average gamer will play for 95 minutes with a standard deviation of 20 minutes. After testing the new reward system with 100 randomly sampled gamers, they found the average play time increased to 125 miutes. Complete the code below using the two-tailed test to determine the p-value, and determine whether this is statistically significant with 95% confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm \n",
    "\n",
    "mean = 95\n",
    "std = 20\n",
    "new_mean = 125\n",
    "\n",
    "# area of right tail \n",
    "p_value_right_tail = 1.0 -  ?\n",
    "\n",
    "# p-value of both tails (symmetrical)\n",
    "p_value = ?\n",
    "\n",
    "print(p_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f748028",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cd268",
   "metadata": {},
   "source": [
    "The p-value is 0.1336, and since this is greater than 0.05 this fails to reject the null hypothesis. This means we cannot say the new reward system made any impact to the gamers' playtimes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm \n",
    "\n",
    "mean = 95\n",
    "std = 20\n",
    "new_mean = 125\n",
    "\n",
    "# area of right tail \n",
    "p_value_right_tail = 1.0 -  norm.cdf(new_mean, mean, std)\n",
    "\n",
    "# p-value of both tails (symmetrical)\n",
    "p_value = p_value_right_tail*2 \n",
    "\n",
    "print(p_value) # 0.13361440253771617"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
